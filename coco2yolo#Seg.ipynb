{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single & Multiple Unzip Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config zip -> upzip\n",
    "\n",
    "SRC_ZIP = r\"to_yolo\\zip\"\n",
    "DST_UNZIP = r\"to_yolo\\unzip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Set 49.zip']\n"
     ]
    }
   ],
   "source": [
    "zip_files = os.listdir(SRC_ZIP)\n",
    "print(zip_files)\n",
    "\n",
    "for zip_ in zip_files:\n",
    "\n",
    "    src = os.path.join(SRC_ZIP, zip_)\n",
    "    folder_name = zip_[:zip_.find('.zip')]\n",
    "    dst = os.path.join(DST_UNZIP, folder_name)\n",
    "\n",
    "    with zipfile.ZipFile(src, 'r') as my_zip:\n",
    "        my_zip.extractall(dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert COCO to YOLO # SEGMANTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config COCO path -> YOLO path\n",
    "\n",
    "SRC_CONVERT_RESULTS = R\"to_yolo\\unzip\"\n",
    "DST_CONVERT_RESULTS = R'to_yolo\\results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Set 49']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "folders = os.listdir(SRC_CONVERT_RESULTS)\n",
    "print(folders)\n",
    "\n",
    "for folder in tqdm(folders):\n",
    "\n",
    "    src = SRC_CONVERT_RESULTS\n",
    "    dst = DST_CONVERT_RESULTS\n",
    "    \n",
    "    with open(os.path.join(src, folder, 'annotations', 'instances_default.json'), 'r') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    images_info = pd.DataFrame(json_data['images'])\n",
    "    annotations = pd.DataFrame(json_data['annotations'])\n",
    "    \n",
    "    os.makedirs(os.path.join(dst, folder+'_yolo'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dst, folder+'_yolo', 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dst, folder+'_yolo', 'labels'), exist_ok=True)\n",
    "\n",
    "    for im_info in images_info.iloc:\n",
    "        anno_select = annotations[annotations['image_id'] == im_info['id']]\n",
    "        \n",
    "        # fix this to flter class \n",
    "        # class_select = anno_select[(anno_select['category_id'] == 1) | (anno_select['category_id'] == 2) | (anno_select['category_id'] == 3)]\n",
    "        class_select = anno_select[(anno_select['category_id'] == 1) | (anno_select['category_id'] == 2)]\n",
    "        \n",
    "        if not class_select.empty:\n",
    "            seg = class_select['segmentation']\n",
    "            text = ''\n",
    "            for index,s in enumerate(seg):\n",
    "\n",
    "                # define class number \n",
    "                cls = class_select['category_id'].values[index]-1 # select all classs default\n",
    "                \n",
    "                sn = [val/im_info['width'] if i%2 == 0 else val/im_info['height'] for i,val in enumerate(s[0])]\n",
    "                text += f'{cls} '\n",
    "                text += ' '.join([f'{val}' for val in sn])\n",
    "                text += '\\n'\n",
    "        else: text = ''\n",
    "        \n",
    "        with open(os.path.join(dst, folder+'_yolo', 'labels', im_info['file_name'][:-4] +'.txt'), 'w') as lb:\n",
    "            lb.write(text)\n",
    "        \n",
    "        shutil.copy(os.path.join(src, folder, 'images', im_info['file_name']) , os.path.join(dst, folder+'_yolo', 'images',im_info['file_name']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spilt data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config split path\n",
    "from pathlib import Path\n",
    "SRC_SPLIT = Path(r'C:\\Users\\JiraponSasomsap\\Downloads\\lime_bboxes\\results')\n",
    "DST_SPLIT = Path(r'C:\\Users\\JiraponSasomsap\\Downloads\\lime_bboxes\\split')\n",
    "\n",
    "FRIST_RUNNING = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "assert FRIST_RUNNING\n",
    "\n",
    "RATIO = (0.8, 0.2, 0.0)\n",
    "\n",
    "def split_data(items, train, val , test):\n",
    "    set_names = 'train,val,test'.split(',')\n",
    "\n",
    "    assert train + val + test == 1.0, \"train, val, and test splits must add up to 1.0\"\n",
    "    \n",
    "    train_n = round(len(items)*train)\n",
    "    val_n = round(len(items)*val)\n",
    "    \n",
    "    train_set = items[:train_n]\n",
    "    val_set = items[train_n:train_n + val_n]\n",
    "    test_set = items[train_n + val_n:]\n",
    "\n",
    "    for spt_items, set_name in zip((train_set, val_set, test_set), set_names):\n",
    "        # print(set_name, spt_items)\n",
    "        for item in spt_items:\n",
    "            dst = Path(DST_SPLIT / ''.join([str(item.parent).split('\\\\')[2], '_split']) / set_name)\n",
    "            os.makedirs(dst / 'images', exist_ok=True)  \n",
    "            os.makedirs(dst / 'labels', exist_ok=True)\n",
    "            shutil.copy(item, dst / 'images' / item.name)\n",
    "            lb = [i for i in Path(SRC_SPLIT).glob(f'*/labels/{item.stem}.txt')][0]\n",
    "            shutil.copy(lb, dst / 'labels' / lb.name)\n",
    "\n",
    "for img_items in tqdm([i for i in SRC_SPLIT.glob('*/images')]):\n",
    "    items = [item for item in img_items.glob('*.jpg')]\n",
    "    # print(items)\n",
    "    random.shuffle(items)\n",
    "    # print(items)\n",
    "    split_data(items, *RATIO)\n",
    "\n",
    "FRIST_RUNNING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
